{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOTNOI Basic NLP Workshop ครั้งที่ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Problem : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "นำ Dataset จาก Truevoice มาทำนายการจำแนกประเภท (Classification) ของ Text \n",
    "Credit : https://github.com/PyThaiNLP/truevoice-intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruxpolth/Desktop/Botnoi DS Project/truevoice-intent\n"
     ]
    }
   ],
   "source": [
    "cd /Users/ruxpolth/Desktop/Botnoi DS Project/truevoice-intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mNote.txt\u001b[m\u001b[m*       \u001b[31mmari_test.csv\u001b[m\u001b[m*  \u001b[31mmari_train.csv\u001b[m\u001b[m*\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train_df = pd.read_csv('mari_train.csv')\n",
    "test_df = pd.read_csv('mari_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>texts_deepcut</th>\n",
       "      <th>action</th>\n",
       "      <th>object</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต . บ...</td>\n",
       "      <td>ผม ไป จ่าย เงิน ที่ Counter Services เค้า เช็...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>payment</td>\n",
       "      <td>billing and payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
       "      <td>internet ยัง ความ เร็ว อยุ่ เท่า ไหร ครับ</td>\n",
       "      <td>enquire</td>\n",
       "      <td>package</td>\n",
       "      <td>promotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
       "      <td>ตะกี้ ไป ชำระ ค่า บริการ ไป แล้ว แต่ ยัง ใช้ ...</td>\n",
       "      <td>report</td>\n",
       "      <td>suspend</td>\n",
       "      <td>billing and payment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
       "      <td>พี่ ค่ะ ยัง ใช้ internet ไม่ ได้ เลย ค่ะ เป็น...</td>\n",
       "      <td>enquire</td>\n",
       "      <td>internet</td>\n",
       "      <td>internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
       "      <td>ฮาโหล คะ พอดี ว่า เมื่อ วาน เปิด ซิม ทรูมูฟ แ...</td>\n",
       "      <td>report</td>\n",
       "      <td>phone_issues</td>\n",
       "      <td>billing and payment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               texts  \\\n",
       "0   ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต . บ...   \n",
       "1               internet ยังความเร็วอยุ่เท่าไหร ครับ   \n",
       "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   \n",
       "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...   \n",
       "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   \n",
       "\n",
       "                                       texts_deepcut   action        object  \\\n",
       "0   ผม ไป จ่าย เงิน ที่ Counter Services เค้า เช็...  enquire       payment   \n",
       "1          internet ยัง ความ เร็ว อยุ่ เท่า ไหร ครับ  enquire       package   \n",
       "2   ตะกี้ ไป ชำระ ค่า บริการ ไป แล้ว แต่ ยัง ใช้ ...   report       suspend   \n",
       "3   พี่ ค่ะ ยัง ใช้ internet ไม่ ได้ เลย ค่ะ เป็น...  enquire      internet   \n",
       "4   ฮาโหล คะ พอดี ว่า เมื่อ วาน เปิด ซิม ทรูมูฟ แ...   report  phone_issues   \n",
       "\n",
       "           destination  \n",
       "0  billing and payment  \n",
       "1           promotions  \n",
       "2  billing and payment  \n",
       "3             internet  \n",
       "4  billing and payment  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "billing and payment      0.386970\n",
       "promotions               0.242600\n",
       "other queries            0.172888\n",
       "internet                 0.143906\n",
       "international dialing    0.025968\n",
       "true money               0.015534\n",
       "lost and stolen          0.012134\n",
       "Name: destination, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['destination'].value_counts() / len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "billing and payment      1.547281\n",
       "promotions               0.970025\n",
       "other queries            0.691286\n",
       "internet                 0.575402\n",
       "international dialing    0.103832\n",
       "true money               0.062114\n",
       "lost and stolen          0.048517\n",
       "Name: destination, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['destination'].value_counts() / len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จาก Dataset จะเห็นได้ว่ามีการตัดคำด้วย Module ของ Deepcut มาให้แล้ว แต่ในกลุ่มย่อยมีความเห็นว่า ขอลอง Module ตัดคำของ PythaiNLP ที่เป็น Engine newmm จะได้ผลลัพธ์เป็นอย่างไร"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#เรียก Module ของ PythaiNLP \n",
    "from pythainlp import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง Function ในการตัดคำ และ ทำความสะอาดข้อมูล\n",
    "def get_th_token(text):\n",
    "    #For Lower/Upper\n",
    "    text = text.lower()\n",
    "    #For Remove line breaks\n",
    "    text = text.replace('\\n',' ')\n",
    "    token = word_tokenize(text)\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ฉัน', 'ไป', 'โรงเรียน']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ลองเรียกใช้ Function\n",
    "get_th_token('ฉันไปโรงเรียน')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เรียกใช้ Module CountVectorizer เพื่อแปลงข้อความให้เป็นตัวเลข\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เแทนที่ Mudule ตัดคำภาษาไทยด้วย Func ที่สร้างไว้ ลงใน Module CountVectorizer และเรียกใช้ N-Gram เพื่อช่วยในการแยกคำ\n",
    "vectorizer = CountVectorizer(tokenizer=get_th_token, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ['ฉันไปโรงเรียน','โรงเรียนของเราหน้าอยู่','คุณครูใจดีทุกคน','ปลากินพี่วิน']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function get_th_token at 0x11fc3a5f0>,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['กิน',\n",
       " 'กิน พี่',\n",
       " 'ของ',\n",
       " 'ของ เรา',\n",
       " 'คุณครู',\n",
       " 'คุณครู ใจดี',\n",
       " 'ฉัน',\n",
       " 'ฉัน ไป',\n",
       " 'ทุกคน',\n",
       " 'ปลา',\n",
       " 'ปลา กิน',\n",
       " 'พี่',\n",
       " 'พี่ วิน',\n",
       " 'วิน',\n",
       " 'หน้า',\n",
       " 'หน้า อยู่',\n",
       " 'อยู่',\n",
       " 'เรา',\n",
       " 'เรา หน้า',\n",
       " 'โรงเรียน',\n",
       " 'โรงเรียน ของ',\n",
       " 'ใจดี',\n",
       " 'ใจดี ทุกคน',\n",
       " 'ไป',\n",
       " 'ไป โรงเรียน']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "        0, 1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['โรงเรียนไปโรงเรียน']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_df['texts']\n",
    "test_data = test_df['texts']\n",
    "\n",
    "train_label = train_df['destination']\n",
    "test_label = test_df['destination']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=get_th_token, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=<function get_th_token at 0x11fc3a5f0>,\n",
       "                vocabulary=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat = vectorizer.transform(train_data)\n",
    "test_feat = vectorizer.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12939, 32832)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12939x32832 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 318137 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat_norm = normalize(train_feat)\n",
    "test_feat_norm = normalize(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearSVC(random_state=0, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_feat_norm, train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(test_feat_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "  billing and payment     0.9271    0.8976    0.9121       977\n",
      "international dialing     0.9216    0.9261    0.9238       203\n",
      "             internet     0.8448    0.9203    0.8809       615\n",
      "      lost and stolen     0.9896    0.9745    0.9820       196\n",
      "        other queries     0.8630    0.8488    0.8558       549\n",
      "           promotions     0.9263    0.8949    0.9103       590\n",
      "           true money     0.9115    0.9717    0.9406       106\n",
      "\n",
      "             accuracy                         0.9020      3236\n",
      "            macro avg     0.9120    0.9191    0.9151      3236\n",
      "         weighted avg     0.9033    0.9020    0.9022      3236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, predict, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[877   2  45   1  29  14   9]\n",
      " [  6 188   4   0   0   5   0]\n",
      " [ 15   0 566   0  23  11   0]\n",
      " [  1   0   0 191   4   0   0]\n",
      " [ 32   1  36   1 466  12   1]\n",
      " [ 15  13  19   0  15 528   0]\n",
      " [  0   0   0   0   3   0 103]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(test_label, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จาก Dataset ของ Truevoice หากเราใช้ Module ตัดคำของ PythaiNLP(engine=newmn) --ใช้เทคนิคแปลงคำเป็นตัวเลขด้วย Bag of word และ N-Gram ในที่นี้ใช้เป็น 2-Gram\n",
    "-- ใช้ L2 Normalize เพื่อแก้ปัญหาความเหมือนกันของ Matrix --ใช้ Model Linear SVC จะได้ accuracy = 90.20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
